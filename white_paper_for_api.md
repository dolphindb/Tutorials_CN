# DolphinDB API白皮书

## 1. 概述

DolphinDB API是供三方应用访问的编程接口，API调用DolphinDB内部资源。
根据DolphinDB在整体IT体系中的定位不同，API的常用场景有如下几个：
* 数据写入: 将DolphinDB作为高频时序数据的存储和分析工具。通过API接收实时数据，清洗转换之后写入DolphinDB是API的最常用场景。
* 复杂计算逻辑迁移：对时序数据做同样分析处理，在DolphinDB中性能要远超原有实现时，可以通过在DolphinDB中用脚本实现后，封装成函数视图供API调用，在尽少改动原有逻辑代码的情况，大幅提升应用的运行性能。
* 数据读取: 当DolphinDB作为数据中台使用时，通过在DolphinDB做清洗重采样等工作，应用通过API将处理结果取出并在应用中使用。

## 2. DolphinDB API的协议和核心功能

DolphinDB API 是基于DolphinDB交互协议实现的客户端软件包。
交互协议部分由DolphinDB Server实现，它约定了指令集和数据交换的报文格式。
协议包含以下几个核心指令：
* connect：连接数据库
* script：将脚本(字符串)提交到DolphinDB执行，并接受脚本返回的结果。此种方式通常用于快速执行一些简单脚本的场景。
* function：调用DolphinDB中定义的函数，并接受函数返回的结果。因为这种方式支持将大数据对象作为参数序列化上传，所以这种方式更适用于调用封装复杂逻辑的函数，并且需要上传大数据集的场景。
* variable：将本地对象上传到DolphinDB并定义为指定名称的变量。若一个数据集在一次连接中会被多次使用，可以通过次方式上传，并在后续脚本中使用。

具体报文格式可以参考[API交互协议](https://gitee.com/dolphindb/Tutorials_CN/blob/master/api_protocol.md)。

API客户端实现负责按约定组织报文和数据序列化工作，并且负责按照编程语言的不同，将反序列化的数据构建成编程语言支持的本地化数据结构。针对不同的编程语言提供专用的API客户端包，具体支持的语言参见[第9章](##9)

## 3. 数据类型
在DolphinDB API支持24种数据类型，主要分为3大类

* 基础类型：

数据类型 | 占用空间
---|---
DT_VOID|1
DT_BOOL|1
DT_BYTE|1
DT_SHORT|2
DT_INT|4
DT_LONG|8
DT_FLOAT|4
DT_DOUBLE|8
DT_SYMBOL|4
DT_STRING|不固定(空格作为截止符)

* 时间类型: DolphinDB中支持非常丰富的时间类型，在存储和传输过程中均使用INT和LONG类型来表示,值为相对于1970.01.01T00:00:00.000的偏移量，用INT还是LONG值表示取决于其精度。

数据类型| 占用空间
---|---
DT_DATE|4
DT_MONTH|4
DT_TIME|4
DT_MINUTE|4
DT_SECOND|4
DT_DATETIME|4
DT_TIMESTAMP|8
DT_NANOTIME|8
DT_NANOTIMESTAMP|8
DT_DATEHOUR|4
DT_DATEMINUTE|4

* 扩展类型: DolphinDB还支持3种128位的类型，针对标准常用的字符串类型如UUID, IP能够更加高效的存储和使用。
    * INT128用128位存储大整型数字。
    * UUID用来存储很多系统中的唯一值。它将长度为32的唯一值字符串用INT128存储，而在API客户端展示为32位文本。
    * IPADDR用于保存IP类型数据，它将IP类型的字符串以INT128类型存储，在API客户端展示为IPV4或IPV6字符串。
    
数据类型| 占用空间
---|---
DT_UUID|16
DT_IPADDR|16
DT_INT128|16

## 4. API异步调用
在需要高吞吐率的场景下，API可以使用异步方式来提交任务。
异步方式提交有如下几个特点：
* API客户端提交任务后，服务端接到任务后客户端即认为任务已完成。
* API客户端无法得知任务在服务端执行的情况和结果。
* API客户端的异步任务提交时间取决于提交参数的序列化及其网络传输时间。

这种方式可以有效提高客户端的任务吞吐量，典型的适用场景是高速小数据量写入场景。
比如，物联网场景下，每个设备毫秒级别采集数据，通过Java 程序订阅设备数据后，通过DolphinDB Java API来写入DolphinDB，因为设备数量多，数据写入单位时间吞吐量需求很高。而且由于行业特性，需要开启实时写盘(dataSync=1)，保证即使断电也不会缓存数据，这种情况下，磁盘的IO压力会很高，容易产生写入数据堆积无法消化的情况。在这种场景，使用异步提交结合CacheEngine(服务端缓存队列)搭配来提升整体IO是不错的方案。

* 异步方式不适用前后任务之间有依赖的场景。比如两个任务，一个任务向分布式数据库写入数据，后一个任务将新写入的数据结合历史数据做分析。这样后一个任务对前一任务有依赖的场景，不能使用异步的方式。




## 5. 高可用
DolphinDB的数据高可用，即使在部分数据节点宕掉的情况下，集群分布式文件系统依然可以正常运转。同样的，用户希望客户端也能实现类似的高可用，比如用户需要使用API定期从分布式数据库中查询数据，计算生成结果然后传输到APP处理保存，这个程序以服务的形式定时运行。那么这个场景下API客户端高可用是非常适用的，因为DolphinDB的数据高可用可以支持部分节点挂掉的情况下仍然能够读取分布式数据库，只要API能够在目标节点宕机的情况下，自动找到任意一个集群中可连接的节点，就可以继续运行，保障业务的持续运转。这个过程不需要人工介入。

DolphinDB的API客户端支持高可用，在服务端节点返回连接异常时，在预先设置的可用节点清单中寻找另一个可用节点重新连接，并且将之前运行的脚本重新提交到新的节点运行。

关于API客户端如何判断节点下线并寻找新的可用节点大致逻辑如下：
```
1. 创建连接时指定高可用参数为true。
2. 接收到连接异常后进入高可用自动连接模式
   2.1.对于当前节点做三次连接重试以确定节点已无法连接。
   2.2.若在初始化连接时指定了highAvailabilitySites(高可用节点清单)参数，那么从清单中随机取一个节点作为可用节点尝试连接，上述过程会一直持续循环直到成功连接上某一个节点为止。
   2.3.若在初始化时未指定highAvailabilitySites参数，那么会连接当前集群的控制器执行`getClusterLiveDataNodes(false)` 函数，获取集群中所有可用节点清单，取第一个作为可用节点进行连接尝试。
3. 连接成功后在console中输出连接到节点的信息。

```

## 6. 数据写入

通过API向DolphinDB写入数据，包含了数据的序列化、上传、Server反序列化数据、写入数据四个过程。

详细分为下述几个步骤
* 将本地数据集序列化成二进制数据流。
* 将写入函数及序列化后的二进制数据上传到DolphinDB。
* DolphinDB 解析报文并反序列化数据集，写入目标数据库。

6.1 批量写入数据

推荐的数据写入接口是使用 function 接口，通过调用DolphinDB的 tableInsert 或者 append!函数，将客户端的本地数据集上传并写入到分布式数据库中。通过这种方式，用户可以一次性向DolphinDB批量写入数据。批量写入数据有诸多好处，首先批量组织数据可以增加压缩比,DolphinDB会对单次写入的数据进行压缩，写入的数据量越大，压缩比会越高。其次，批量写入数据可以提升磁盘IO, 单位时间内写入更多的数据。对于高频的数据源，将单条数据组织成批量再写入，性能要远远高于一条一条写入。关于写入数据量和写入性能的比较，可以参考[API性能评测基准文档]()。

6.2 并行写入数据
要加快写入的速度，还有一种方式是采用并行写入的方式。当写入的批量大小受到业务限制，无法将磁盘的IO性能全部发挥时，可以通过并行写入的方式，更充分的利用磁盘的IO能力。
需要注意的是，分区是 DolphinDB database 存储数据的最小单位。DolphinDB对分区的写入操作是独占式的，当并行写入数据的时候，请避免多任务同时向一个分区写入数据。

要达到并行写入的目的，要在客户端对数据做好规划，要根据分区字段的内容，将同一个分区的数据放到一个线程中处理。这个逻辑需要客户端编程实现, API中提供了PartitionedTableAppender类来实现数据分流和利用线程池并行写入的功能。


## 7. 分块传输
当客户端应用需要传递大量的数据，传输和反序列完成需要较长时间，用户希望能数据来一部分就处理一部分，这样的场景，可以使用分块传输的功能。

分块功能允许用户指定一个fetchSize参数，即分块的大小，指示服务器将数据切分成若干个table, 每个table 包含 fetchSize行数据，最终将所有table组成 tuple的形式返回给客户端。客户端API也会通过 hasNext 和 read 方法来在线读取(反序列化)返回的数据，直到 HasNext返回false为止。这样客户端可以更及时的获得数据，无需等待所有的数据完成传输和反序列化的过程。

需要注意的是，若接受了部分数据之后发现后续的数据已经不需要了，需要显式的调用skipAll方法，将后续数据忽略，若无此步骤，未被读取的数据将会滞留在socket缓冲区，导致后续数据的反序列化失败。

当前已支持的客户端API：Java客户端，C++客户端，Python 客户端。上述内容中的参数和函数名称以Java API为例，其他语言API在命名上可能略有差异，但是概念一致。具体用法可以参考[Java API文档](https://2xdb.net/dolphindb/api-java/-/blob/master/README_CN.md#741-%E8%AF%BB%E5%8F%96%E5%88%86%E5%B8%83%E5%BC%8F%E8%A1%A8)

## 8. 压缩传输
API和服务器的传输通讯过程中，为了进一步提升传输效率，可以对数据进行压缩。目前API支持LZ4和DeltaOfDelta两类压缩方式。

若需要使用压缩传输功能，客户端在开启连接时需要开启compress支持（设置API连接时参数compress=true)。在创建数据表时，可以调用setCompressedMethod对每列指定压缩方法，默认为LZ4压缩。

两种压缩算法的特点：

DeltaOfDelta是针对时间戳提出的压缩算法，由于时间戳具有连续和密集的特征，利用该算法可以极大降低时间戳的存储空间，因此特别适合时序数据的压缩。
LZ4主要对重复字符进行压缩，因此它更追求压缩速度对压缩率提升不明显。
对合适的字段采用压缩算法， 可以在通讯场景下传输更多的数据，显著地提升数据传输吞吐量。

## 9. SSL支持

在API和SERVER之间传递报文和数据时，可以通过SSL方式来保障信息传输的安全性。

要使用此特性，需要服务器端开启SSL支持。在节点配置文件中设置 enableHTTPS = true 启用服务器对SSL支持。

客户端API可以针对不同的连接确定是否启用SSL。用户在建立连接时设置 useSSL = true ，告知客户端API本连接全部使用SSL方式连接服务器。

注意： 服务端和客户端API必须都启用SSL或者都不启用SSL，不允许一方启用另一方不启用的情况。

## 9. 批量异步写入

API的批量写入适用于客户端实时产生数据并需要单行写入服务器的场景。在该场景下，能够非常有效的提升写入性能。
在高频写入少量数据场景下，服务器端存在数据接收速度和其写入磁盘速度不匹配的情况，API就此问题提出了异步批量写入的方案。由于服务器进行I/O的时间较长，从客户端传输过来的数据不能被及时写
入，会滞留于服务器端，增大服务器的开销。同时数据在网络中的单行封装增大了网络的开销，在存盘时也会造成磁盘的碎片化，从而影响后续服务器查询数据的性能。
API在客户端设置了一个数据缓冲队列，在服务器端忙于磁盘I/O的时段，客户端写线程仍然可以持续写入缓冲队列（该队列由API内部维护），并在写入队列后即刻返回，从而避免了写线程的忙等。客户端消
费线程负责消费缓冲队列中的数据，并批量打包传输给服务器端，从而提升服务器的I/O效率。

API支持多线程调用，并提供了查看队列状态以及线程状态的方法。 getStatus() 返回一个元组，包含队列深度，对应的插入表的状态以及后台写入进程的状态。
getAllStatus() 返回一张表，除了 getStatus 返回的基本状态外，还提供了对应写入的数据库和数据表信息以及服务器成功接收的数据量。

批量异步写入不适用如下场景：
不能实时确认每一批数据成功写入。如果后台线程写入过程中出现错误或者服务端异常， 后台线程将退出，并在下一次写入数据时清空队列并抛出异常。

## 10. 支持的编程语言

API客户端提供不同语言的包，当前已经支持的编程语言包有， C++, JAVA, Python, C#, go , rust, node js, R

所有客户端API都有4个基本方法，对应4个协议
* `connect` ： 提供host和port信息，连接到指定节点，使用 connect 协议。
* `run` ： 运行任意可以在dolphindb中执行的脚本字符串，对应 script 协议。
* `run`(function) : 运行指定函数，对应 function 协议。
* `upload`：将API本地变量上传成为dolphindb节点内存中一个命名变量，对应 variable 协议。

语言|环境|网络协议|是否支持流数据订阅|依赖关系
---|---|---|---|---
C++ | Windows & Linux | TCP(SOCKET) | 支持 | 无
JAVA | Java 1.8 及以上运行环境 |TCP(SOCKET) | 支持| 无
Python |支持3.6，3.7，3.8版本 |TCP(SOCKET) | 支持| C++API
nodejs |nodejs 10.21 或以上版本|TCP(SOCKET) | 支持|无
Go | Linux |TCP(SOCKET)|不支持|C++API
Rust |  |TCP(SOCKET)|不支持|C++API
R | |TCP(SOCKET)|不支持|C++API
jsonApi| webAPI方式调用 | http协议，采用json格式交互数据。| 不支持|推荐前端界面直连DolphinDB的场景使用，当前提供javascript语言客户端包。